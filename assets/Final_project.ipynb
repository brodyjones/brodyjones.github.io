{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9QiFa8GHCl8",
        "outputId": "18041f2c-97d1-4b90-dc7f-1df3bc37dd5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 149])\n",
            "Train features shape: torch.Size([700, 98]), Train buoy power targets shape: torch.Size([700, 49]), Train total power targets shape: torch.Size([700])\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## upload out data set, separate initial X,Y locations and correspnonding power outputs\n",
        "\n",
        "file_npath = \"/content/WEC_Perth_49.csv\"\n",
        "\n",
        "df = pd.read_csv(file_npath)\n",
        "df_sample = df.sample(n=1000, random_state=42).reset_index(drop=True)\n",
        "\n",
        "data = torch.tensor(df_sample.values, dtype=torch.float32)\n",
        "print(data.size())\n",
        "\n",
        "XY_s = data[:, :98]\n",
        "Power_s = data[:, 98:147]\n",
        "qW_s = data[:, 147]\n",
        "total_Power_s = data[:, 148]\n",
        "\n",
        "## sum of all Power_s for an instance = total_Power_s\n",
        "\n",
        "## qW_s = total_Power_s / maximum_Power_s\n",
        "\n",
        "\n",
        "# Train-test split for individual buoy power outputs\n",
        "X_train, X_test, y_train_power, y_test_power = train_test_split(XY_s, Power_s, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train-test split for total power output\n",
        "_, _, y_train_total, y_test_total = train_test_split(XY_s, total_Power_s, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Train features shape: {X_train.size()}, Train buoy power targets shape: {y_train_power.size()}, Train total power targets shape: {y_train_total.size()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CustomLoss(nn.Module): ## establish our loss function\n",
        "    def __init__(self, alpha=1.0):\n",
        "        super(CustomLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.mse = nn.MSELoss()\n",
        "\n",
        "    def forward(self, y_pred, y_train_total):\n",
        "        \"\"\"\n",
        "        y_pred: Predicted buoy power outputs (batch_size x 49)\n",
        "        y_train_power: True buoy power outputs (batch_size x 49)\n",
        "        \"\"\"\n",
        "        # Compute MSE for individual buoy power outputs\n",
        "        power_loss = self.mse(y_pred, y_train_total)\n",
        "\n",
        "        # Combine losses with weights\n",
        "        loss = self.alpha * power_loss\n",
        "        return loss"
      ],
      "metadata": {
        "id": "lIrcrwvI-yry"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_model = DecisionTreeRegressor(max_depth=10)\n",
        "tree_model.fit(X_train.numpy(), y_train_total.numpy())\n",
        "y_pred_tree = tree_model.predict(X_test.numpy())\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "RF_model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
        "RF_model.fit(X_train.numpy(), y_train_total.numpy())\n",
        "y_pred_RF = RF_model.predict(X_test.numpy())\n",
        "\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "boost_model = XGBRegressor(n_estimators=100, max_depth=10, learning_rate=0.1)\n",
        "boost_model.fit(X_train.numpy(), y_train_total.numpy())\n",
        "y_pred_boost = boost_model.predict(X_test.numpy())\n",
        "\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "SVR_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
        "SVR_model.fit(X_train.numpy(), y_train_total.numpy())\n",
        "y_pred_SVR = SVR_model.predict(X_test.numpy())\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "KNN_model = KNeighborsRegressor(n_neighbors=5)\n",
        "KNN_model.fit(X_train.numpy(), y_train_total.numpy())\n",
        "y_pred_KNN = KNN_model.predict(X_test.numpy())\n"
      ],
      "metadata": {
        "id": "5qDwR-27_CHr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define the model, loss, and optimizer\n",
        "input_size = X_train.size(1)\n",
        "hidden_size = 64\n",
        "output_size = 1  # For total power prediction\n",
        "NN_model = NeuralNetwork(input_size, hidden_size, output_size)\n",
        "loss_fn = CustomLoss(alpha=1.0)  # Adjust alpha and beta as needed\n",
        "optimizer = optim.Adam(NN_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    NN_model.train()\n",
        "    y_pred = NN_model(X_train)\n",
        "    y_pred = y_pred.squeeze()  # Remove the extra dimension\n",
        "    loss = loss_fn(y_pred, y_train_total)  # Add batch dimension\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# # Evaluation on test set\n",
        "NN_model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_test = NN_model(X_test).squeeze()\n",
        "    test_loss = loss_fn(y_pred_test, y_test_total)\n",
        "    print(f\"Test Loss: {test_loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJMKZmxd_OvT",
        "outputId": "62eedad1-e22d-46be-b646-450be4fa267d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 15175410253824.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = CustomLoss(alpha=1.0)\n",
        "\n",
        "print(\"Decision Tree: \")\n",
        "y_pred_tree_tensor = torch.tensor(y_pred_tree, dtype=torch.float32)\n",
        "test_loss = loss_fn(y_pred_tree_tensor, y_test_total)\n",
        "print(f\"Test Loss: {test_loss.item():.4f}\")\n",
        "\n",
        "print(\"Random Forest: \")\n",
        "y_pred_RF_tensor = torch.tensor(y_pred_RF, dtype=torch.float32)\n",
        "test_loss = loss_fn(y_pred_RF_tensor, y_test_total)\n",
        "print(f\"Test Loss: {test_loss.item():.4f}\")\n",
        "\n",
        "print(\"Boost: \")\n",
        "y_pred_boost_tensor = torch.tensor(y_pred_boost, dtype=torch.float32)\n",
        "test_loss = loss_fn(y_pred_boost_tensor, y_test_total)\n",
        "print(f\"Test Loss: {test_loss.item():.4f}\")\n",
        "\n",
        "print(\"SVR: \")\n",
        "y_pred_SVR_tensor = torch.tensor(y_pred_SVR, dtype=torch.float32)\n",
        "test_loss = loss_fn(y_pred_SVR_tensor, y_test_total)\n",
        "print(f\"Test Loss: {test_loss.item():.4f}\")\n",
        "\n",
        "print(\"KNN: \")\n",
        "y_pred_KNN_tensor = torch.tensor(y_pred_KNN, dtype=torch.float32)\n",
        "test_loss = loss_fn(y_pred_KNN_tensor, y_test_total)\n",
        "print(f\"Test Loss: {test_loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GmYaW8XjKF7",
        "outputId": "b18f19ee-f2a9-433b-e943-ce62dae81acd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree: \n",
            "Test Loss: 4782450176.0000\n",
            "Random Forest: \n",
            "Test Loss: 2441870592.0000\n",
            "Boost: \n",
            "Test Loss: 2361456896.0000\n",
            "SVR: \n",
            "Test Loss: 14457721856.0000\n",
            "KNN: \n",
            "Test Loss: 4775132672.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implements multi-output regression models for the task of individual buoy power output prediction.\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_model = DecisionTreeRegressor(max_depth=10)\n",
        "tree_model.fit(X_train.numpy(), y_train_power.numpy())\n",
        "y_pred_tree_multi = tree_model.predict(X_test.numpy())\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "RF_model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
        "RF_model.fit(X_train.numpy(), y_train_power.numpy())\n",
        "y_pred_RF_multi = RF_model.predict(X_test.numpy())\n",
        "\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "boost_model = XGBRegressor(n_estimators=100, max_depth=10, learning_rate=0.1)\n",
        "boost_model.fit(X_train.numpy(), y_train_power.numpy())\n",
        "y_pred_boost_multi = boost_model.predict(X_test.numpy())\n",
        "\n",
        "\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Wrap SVR in MultiOutputRegressor\n",
        "SVR_model = MultiOutputRegressor(SVR(kernel='rbf', C=1.0, epsilon=0.1))\n",
        "SVR_model.fit(X_train.numpy(), y_train_power.numpy())  # y_train_power shape: (batch_size, 49)\n",
        "y_pred_SVR = SVR_model.predict(X_test.numpy())\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "KNN_model = KNeighborsRegressor(n_neighbors=5)\n",
        "KNN_model.fit(X_train.numpy(), y_train_power.numpy())\n",
        "y_pred_KNN = KNN_model.predict(X_test.numpy())"
      ],
      "metadata": {
        "id": "3aYoYGGssq8B"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Decision Tree: \")\n",
        "test_loss = nn.MSELoss()(torch.tensor(y_pred_tree_multi, dtype=torch.float32), y_test_power)\n",
        "print(f\"Test Loss: {test_loss.item():.4f}\")\n",
        "\n",
        "print(\"Random Forest: \")\n",
        "test_loss = nn.MSELoss()(torch.tensor(y_pred_RF_multi, dtype=torch.float32), y_test_power)\n",
        "print(f\"Test Loss: {test_loss.item():.4f}\")\n",
        "\n",
        "print(\"Boost: \")\n",
        "test_loss = nn.MSELoss()(torch.tensor(y_pred_boost_multi, dtype=torch.float32), y_test_power)\n",
        "print(f\"Test Loss: {test_loss.item():.4f}\")\n",
        "\n",
        "print(\"SVR: \")\n",
        "test_loss = nn.MSELoss()(torch.tensor(y_pred_SVR, dtype=torch.float32), y_test_power)\n",
        "print(f\"Test Loss: {test_loss.item():.4f}\")\n",
        "\n",
        "print(\"KNN: \")\n",
        "test_loss = nn.MSELoss()(torch.tensor(y_pred_KNN, dtype=torch.float32), y_test_power)\n",
        "print(f\"Test Loss: {test_loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grB0sU8wtoKv",
        "outputId": "182e7531-e81b-4664-d815-31e9cb8bffbf"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree: \n",
            "Test Loss: 64288484.0000\n",
            "Random Forest: \n",
            "Test Loss: 40985464.0000\n",
            "Boost: \n",
            "Test Loss: 24024452.0000\n",
            "SVR: \n",
            "Test Loss: 126940368.0000\n",
            "KNN: \n",
            "Test Loss: 47109600.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_inter_buoy_distances(XY_s, num_buoys=49):\n",
        "    distances = []\n",
        "    for i in range(num_buoys):\n",
        "        for j in range(i + 1, num_buoys):\n",
        "            dist = torch.sqrt((XY_s[:, 2*i] - XY_s[:, 2*j])**2 + (XY_s[:, 2*i+1] - XY_s[:, 2*j+1])**2)\n",
        "            distances.append(dist)\n",
        "    return torch.stack(distances, dim=1)\n",
        "\n",
        "# Compute inter-buoy distances and add to features\n",
        "inter_buoy_distances_train = compute_inter_buoy_distances(X_train)\n",
        "inter_buoy_distances_test = compute_inter_buoy_distances(X_test)\n",
        "\n",
        "# Concatenate distances to XY features\n",
        "X_train = torch.cat((X_train, inter_buoy_distances_train), dim=1)\n",
        "X_test = torch.cat((X_test, inter_buoy_distances_test), dim=1)\n",
        "\n",
        "print(f\"Enhanced train features shape: {X_train.size()}, Test features shape: {X_test.size()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Xbu-ThChR9j",
        "outputId": "756b49da-a148-485b-95e5-d0edc7ab926e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced train features shape: torch.Size([700, 1274]), Test features shape: torch.Size([300, 1274])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "## Use randomized search to find best hyperparameters for predicting TOTAL power output\n",
        "\n",
        "# Define model\n",
        "xgb = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "# Hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300, 500],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'min_child_weight': [1, 3, 5, 7],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'gamma': [0, 1, 5],\n",
        "    'reg_alpha': [0, 1, 10],\n",
        "    'reg_lambda': [1, 5, 10],\n",
        "}\n",
        "\n",
        "# Randomized Search\n",
        "search = RandomizedSearchCV(xgb, param_distributions=param_grid, n_iter=100, cv=3, scoring='neg_mean_squared_error', verbose=1, random_state=42, n_jobs=-1)\n",
        "search.fit(X_train.numpy(), y_train_total.numpy())\n",
        "\n",
        "# Best model\n",
        "best_xgb = search.best_estimator_\n",
        "print(\"Best model:\", best_xgb)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best parameters:\", search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWWKCS8q858z",
        "outputId": "3744d0df-1ae7-493a-b56a-611ae49b96d9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
            "Best model: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
            "             colsample_bylevel=None, colsample_bynode=None,\n",
            "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
            "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "             gamma=5, grow_policy=None, importance_type=None,\n",
            "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
            "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
            "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
            "             multi_strategy=None, n_estimators=300, n_jobs=None,\n",
            "             num_parallel_tree=None, random_state=42, ...)\n",
            "Best parameters: {'subsample': 0.8, 'reg_lambda': 10, 'reg_alpha': 1, 'n_estimators': 300, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.1, 'gamma': 5, 'colsample_bytree': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred_best_boost = best_xgb.predict(X_test.numpy())\n",
        "print(\"Best Boost: \")\n",
        "test_loss = loss_fn(torch.tensor(y_pred_best_boost, dtype=torch.float32), y_test_total)\n",
        "print(f\"Test Loss: {test_loss.item():.4f}\")\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR5WQMfP_LtO",
        "outputId": "5d3f7b42-bb6c-4747-99df-a2baeb0503d2"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Boost: \n",
            "Test Loss: 1594093056.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Use randomized search to find best hyperparameters for predicting INDIVIDUAL power output\n",
        "\n",
        "best_xgb = XGBRegressor(subsample=0.8, reg_lambda=10, reg_alpha=1, n_estimators=300, min_child_weight=1, max_depth=3, learning_rate=0.1, colsample_bytree=1.0, gamma=5, random_state=42)\n",
        "best_xgb.fit(X_train.numpy(), y_train_power.numpy())\n",
        "y_pred_best_boost_multi = best_xgb.predict(X_test.numpy())\n",
        "\n",
        "print(\"Best Boost: \")\n",
        "test_loss = loss_fn(torch.tensor(y_pred_best_boost_multi, dtype=torch.float32), y_test_power)\n",
        "print(f\"Test Loss: {test_loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPx-bUbhACCG",
        "outputId": "66e60895-52f6-41c2-ae3f-135658938843"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Boost: \n",
            "Test Loss: 22498574.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define model\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False],\n",
        "}\n",
        "\n",
        "# Grid Search\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
        "grid_search.fit(X_train.numpy(), y_train_total.numpy())\n",
        "\n",
        "# Best model\n",
        "best_rf = grid_search.best_estimator_\n",
        "print(\"Best model:\", best_rf)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klf6i36JRc4w",
        "outputId": "7ff45f51-8438-40d2-ffab-4d8634bd2ff1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 432 candidates, totalling 1296 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model: RandomForestRegressor(bootstrap=False, max_depth=30, max_features='sqrt',\n",
            "                      n_estimators=300, random_state=42)\n",
            "Best parameters: {'bootstrap': False, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = CustomLoss(alpha=1.0)\n",
        "\n",
        "best_rf = RandomForestRegressor(bootstrap=False, max_depth=30, max_features='sqrt',\n",
        "                      n_estimators=300, random_state=42)\n",
        "best_rf.fit(X_train.numpy(), y_train_total.numpy())\n",
        "y_pred_best_RF = best_rf.predict(X_test.numpy())\n",
        "\n",
        "print(\"Best RF_total: \")\n",
        "test_loss = loss_fn(torch.tensor(y_pred_best_RF, dtype=torch.float32), y_test_total)\n",
        "print(f\"Test Loss: {test_loss.item():.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "## Now for individual power outputs\n",
        "\n",
        "best_rf = RandomForestRegressor(bootstrap=False, max_depth=30, max_features='sqrt',\n",
        "                      n_estimators=300, random_state=42)\n",
        "best_rf.fit(X_train.numpy(), y_train_power.numpy())\n",
        "y_pred_best_RF_multi = best_rf.predict(X_test.numpy())\n",
        "\n",
        "print(\"Best RF_power: \")\n",
        "test_loss = loss_fn(torch.tensor(y_pred_best_RF_multi, dtype=torch.float32), y_test_power)\n",
        "print(f\"Test Loss: {test_loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBTlZK66Xn_Y",
        "outputId": "e05e729f-ff06-4fcf-8cf0-5f0bf5cb24fc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RF_total: \n",
            "Test Loss: 2033772800.0000\n",
            "Best RF_power: \n",
            "Test Loss: 35088712.0000\n"
          ]
        }
      ]
    }
  ]
}